{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Purna8989/CIFAKE-Image-Classification-and-Explainable-Identification-of-AI-Generated-Synthetic-Images/blob/main/project_CIFAKE_Complete.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpO53me9ru3n",
        "outputId": "e6d8116b-470c-484b-e67d-ee9eafdf8e83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.utils import image_dataset_from_directory\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Rescaling, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Activation, Dropout\n",
        "from keras.metrics import Precision, Recall\n",
        "\n",
        "import keras_tuner as kt\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "56JsQyQWrvrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "# Define paths\n",
        "zip_path = '/content/dataset.zip'\n",
        "top_dir = '/content/dataset'\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(top_dir)\n",
        "\n",
        "# Define train and test directories after extraction\n",
        "train_dir = os.path.join(top_dir, 'train')\n",
        "test_dir = os.path.join(top_dir, 'test')\n",
        "\n",
        "# List REAL and FAKE images in the training directory\n",
        "train_real = os.listdir(os.path.join(train_dir, 'REAL'))\n",
        "train_fake = os.listdir(os.path.join(train_dir, 'FAKE'))\n",
        "\n",
        "\n",
        "# List REAL and FAKE images in the testing directory\n",
        "test_real = os.listdir(os.path.join(test_dir, 'REAL'))\n",
        "test_fake = os.listdir(os.path.join(test_dir, 'FAKE'))\n",
        "\n",
        "print(\"Number of real images in training set:\", len(train_real))\n",
        "print(\"Number of fake images in training set:\", len(train_fake))\n",
        "print(\"Number of real images in testing set:\", len(test_real))\n",
        "print(\"Number of fake images in testing set:\", len(test_fake))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vixVHsgzrvwR",
        "outputId": "9e98523b-7031-46cf-ee77-b1a3c8c348a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of real images in training set: 50000\n",
            "Number of fake images in training set: 50000\n",
            "Number of real images in testing set: 10000\n",
            "Number of fake images in testing set: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  # Import TensorFlow\n",
        "from keras.utils import image_dataset_from_directory\n",
        "\n",
        "# Load training and validation datasets\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    label_mode='binary',\n",
        "    batch_size=32,\n",
        "    image_size=(32, 32)\n",
        ")\n",
        "\n",
        "val_dataset = image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    label_mode='binary',\n",
        "    batch_size=32,\n",
        "    image_size=(32, 32)\n",
        ")\n",
        "\n",
        "# Optimize dataset loading\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(\"Training and validation datasets loaded successfully.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh05VtsOrvxi",
        "outputId": "80422967-6c01-4e2f-bf2b-2381b62bdccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 100000 files belonging to 2 classes.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "Training and validation datasets loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_model(filters, layers):\n",
        "    \"\"\"\n",
        "    Creates a CNN model with the specified number of filters and layers.\n",
        "    Args:\n",
        "        filters (int): Number of filters in the convolutional layers.\n",
        "        layers (int): Number of convolutional layers.\n",
        "\n",
        "    Returns:\n",
        "        Sequential: Compiled CNN model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    # Rescaling layer\n",
        "    model.add(Rescaling(1./255, input_shape=(32, 32, 3)))\n",
        "\n",
        "    # Add convolutional and pooling layers\n",
        "    for _ in range(layers):\n",
        "        model.add(Conv2D(filters, (3, 3), padding='same'))\n",
        "        model.add(BatchNormalization())\n",
        "        model.add(Activation('relu'))\n",
        "        model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "    # Flatten and output layer\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))  # Binary classification\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy', Precision(), Recall()])\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "0saq6PW2sFYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define topologies: [(filters, layers)]\n",
        "topologies = [\n",
        "    (16, 1), (16, 2), (16, 3),\n",
        "    (32, 1), (32, 2), (32, 3),\n",
        "    (64, 1), (64, 2), (64, 3),\n",
        "    (128, 1), (128, 2), (128, 3)\n",
        "]\n",
        "\n",
        "results = []\n",
        "\n",
        "# Train and evaluate each topology\n",
        "for filters, layers in topologies:\n",
        "    print(f\"Training model with {filters} filters and {layers} layers...\")\n",
        "\n",
        "    # Create model\n",
        "    model = create_cnn_model(filters, layers)\n",
        "\n",
        "    # Train model\n",
        "    history = model.fit(\n",
        "        train_dataset,\n",
        "        validation_data=val_dataset,\n",
        "        epochs=3,\n",
        "        verbose=2,\n",
        "        callbacks=[EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)]\n",
        "    )\n",
        "\n",
        "    # Evaluate model\n",
        "    val_metrics = model.evaluate(val_dataset, verbose=0)\n",
        "    precision = val_metrics[2]\n",
        "    recall = val_metrics[3]\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "    # Append results\n",
        "    results.append({\n",
        "        'Filters': filters,\n",
        "        'Layers': layers,\n",
        "        'Accuracy': val_metrics[1],\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1 Score': f1_score,\n",
        "        'Validation Loss': val_metrics[0]\n",
        "    })\n",
        "\n",
        "# Convert results to a DataFrame for visualization\n",
        "results_df = pd.DataFrame(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFmw8XlYsIDK",
        "outputId": "d9748ee9-d75f-4379-f0fa-5cd750db09f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training model with 16 filters and 1 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 22s - loss: 0.3857 - accuracy: 0.8276 - precision: 0.8218 - recall: 0.8366 - val_loss: 0.3383 - val_accuracy: 0.8537 - val_precision: 0.7975 - val_recall: 0.9483 - 22s/epoch - 7ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 21s - loss: 0.2883 - accuracy: 0.8825 - precision: 0.8774 - recall: 0.8893 - val_loss: 0.4428 - val_accuracy: 0.8092 - val_precision: 0.7292 - val_recall: 0.9838 - 21s/epoch - 7ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 20s - loss: 0.2602 - accuracy: 0.8952 - precision: 0.8915 - recall: 0.8999 - val_loss: 0.2429 - val_accuracy: 0.9085 - val_precision: 0.9053 - val_recall: 0.9124 - 20s/epoch - 7ms/step\n",
            "Training model with 16 filters and 2 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 31s - loss: 0.2994 - accuracy: 0.8733 - precision_1: 0.8673 - recall_1: 0.8814 - val_loss: 0.3206 - val_accuracy: 0.8581 - val_precision_1: 0.7952 - val_recall_1: 0.9647 - 31s/epoch - 10ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 30s - loss: 0.2262 - accuracy: 0.9101 - precision_1: 0.9063 - recall_1: 0.9147 - val_loss: 0.2256 - val_accuracy: 0.9118 - val_precision_1: 0.9373 - val_recall_1: 0.8826 - 30s/epoch - 10ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 30s - loss: 0.2070 - accuracy: 0.9183 - precision_1: 0.9155 - recall_1: 0.9216 - val_loss: 0.2707 - val_accuracy: 0.8881 - val_precision_1: 0.8339 - val_recall_1: 0.9692 - 30s/epoch - 10ms/step\n",
            "Training model with 16 filters and 3 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 38s - loss: 0.2762 - accuracy: 0.8839 - precision_2: 0.8782 - recall_2: 0.8916 - val_loss: 0.2432 - val_accuracy: 0.8980 - val_precision_2: 0.8548 - val_recall_2: 0.9589 - 38s/epoch - 12ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 35s - loss: 0.2091 - accuracy: 0.9165 - precision_2: 0.9131 - recall_2: 0.9208 - val_loss: 0.2292 - val_accuracy: 0.9057 - val_precision_2: 0.9082 - val_recall_2: 0.9027 - 35s/epoch - 11ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 35s - loss: 0.1889 - accuracy: 0.9253 - precision_2: 0.9224 - recall_2: 0.9287 - val_loss: 0.3044 - val_accuracy: 0.8767 - val_precision_2: 0.8232 - val_recall_2: 0.9594 - 35s/epoch - 11ms/step\n",
            "Training model with 32 filters and 1 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 27s - loss: 0.3893 - accuracy: 0.8288 - precision_3: 0.8235 - recall_3: 0.8371 - val_loss: 0.3992 - val_accuracy: 0.8285 - val_precision_3: 0.7653 - val_recall_3: 0.9478 - 27s/epoch - 8ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 25s - loss: 0.2722 - accuracy: 0.8889 - precision_3: 0.8836 - recall_3: 0.8960 - val_loss: 0.7053 - val_accuracy: 0.7250 - val_precision_3: 0.9879 - val_recall_3: 0.4555 - 25s/epoch - 8ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 25s - loss: 0.2448 - accuracy: 0.9024 - precision_3: 0.8993 - recall_3: 0.9063 - val_loss: 0.2415 - val_accuracy: 0.9036 - val_precision_3: 0.8798 - val_recall_3: 0.9348 - 25s/epoch - 8ms/step\n",
            "Training model with 32 filters and 2 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 39s - loss: 0.2830 - accuracy: 0.8812 - precision_4: 0.8770 - recall_4: 0.8867 - val_loss: 0.2300 - val_accuracy: 0.9100 - val_precision_4: 0.9193 - val_recall_4: 0.8988 - 39s/epoch - 12ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 38s - loss: 0.2105 - accuracy: 0.9165 - precision_4: 0.9137 - recall_4: 0.9199 - val_loss: 0.2276 - val_accuracy: 0.9086 - val_precision_4: 0.9153 - val_recall_4: 0.9005 - 38s/epoch - 12ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 38s - loss: 0.1902 - accuracy: 0.9247 - precision_4: 0.9226 - recall_4: 0.9271 - val_loss: 0.2087 - val_accuracy: 0.9176 - val_precision_4: 0.9515 - val_recall_4: 0.8802 - 38s/epoch - 12ms/step\n",
            "Training model with 32 filters and 3 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 46s - loss: 0.2499 - accuracy: 0.8966 - precision_5: 0.8917 - recall_5: 0.9028 - val_loss: 0.2278 - val_accuracy: 0.9072 - val_precision_5: 0.8918 - val_recall_5: 0.9268 - 46s/epoch - 15ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 44s - loss: 0.1878 - accuracy: 0.9259 - precision_5: 0.9243 - recall_5: 0.9279 - val_loss: 0.2210 - val_accuracy: 0.9143 - val_precision_5: 0.9613 - val_recall_5: 0.8633 - 44s/epoch - 14ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 44s - loss: 0.1677 - accuracy: 0.9341 - precision_5: 0.9326 - recall_5: 0.9359 - val_loss: 0.2766 - val_accuracy: 0.8916 - val_precision_5: 0.9818 - val_recall_5: 0.7980 - 44s/epoch - 14ms/step\n",
            "Training model with 64 filters and 1 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 36s - loss: 0.3767 - accuracy: 0.8401 - precision_6: 0.8358 - recall_6: 0.8465 - val_loss: 0.2925 - val_accuracy: 0.8773 - val_precision_6: 0.8403 - val_recall_6: 0.9316 - 36s/epoch - 11ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 34s - loss: 0.2636 - accuracy: 0.8959 - precision_6: 0.8922 - recall_6: 0.9006 - val_loss: 0.3205 - val_accuracy: 0.8650 - val_precision_6: 0.9465 - val_recall_6: 0.7737 - 34s/epoch - 11ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 34s - loss: 0.2343 - accuracy: 0.9072 - precision_6: 0.9040 - recall_6: 0.9111 - val_loss: 0.9873 - val_accuracy: 0.6942 - val_precision_6: 0.9819 - val_recall_6: 0.3957 - 34s/epoch - 11ms/step\n",
            "Training model with 64 filters and 2 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 56s - loss: 0.2795 - accuracy: 0.8837 - precision_7: 0.8804 - recall_7: 0.8880 - val_loss: 0.2283 - val_accuracy: 0.9105 - val_precision_7: 0.9386 - val_recall_7: 0.8785 - 56s/epoch - 18ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 54s - loss: 0.2048 - accuracy: 0.9178 - precision_7: 0.9158 - recall_7: 0.9202 - val_loss: 0.1971 - val_accuracy: 0.9205 - val_precision_7: 0.9068 - val_recall_7: 0.9374 - 54s/epoch - 17ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 54s - loss: 0.1775 - accuracy: 0.9301 - precision_7: 0.9282 - recall_7: 0.9324 - val_loss: 0.3138 - val_accuracy: 0.8756 - val_precision_7: 0.9732 - val_recall_7: 0.7726 - 54s/epoch - 17ms/step\n",
            "Training model with 64 filters and 3 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 65s - loss: 0.2476 - accuracy: 0.8982 - precision_8: 0.8941 - recall_8: 0.9033 - val_loss: 0.2844 - val_accuracy: 0.8805 - val_precision_8: 0.8834 - val_recall_8: 0.8767 - 65s/epoch - 21ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 64s - loss: 0.1770 - accuracy: 0.9304 - precision_8: 0.9286 - recall_8: 0.9324 - val_loss: 0.2009 - val_accuracy: 0.9194 - val_precision_8: 0.9204 - val_recall_8: 0.9182 - 64s/epoch - 20ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 64s - loss: 0.1516 - accuracy: 0.9406 - precision_8: 0.9396 - recall_8: 0.9418 - val_loss: 0.1812 - val_accuracy: 0.9297 - val_precision_8: 0.9362 - val_recall_8: 0.9223 - 64s/epoch - 21ms/step\n",
            "Training model with 128 filters and 1 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 53s - loss: 0.4045 - accuracy: 0.8330 - precision_9: 0.8273 - recall_9: 0.8416 - val_loss: 0.6019 - val_accuracy: 0.7350 - val_precision_9: 0.9606 - val_recall_9: 0.4900 - 53s/epoch - 17ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 51s - loss: 0.2620 - accuracy: 0.8957 - precision_9: 0.8913 - recall_9: 0.9013 - val_loss: 0.2986 - val_accuracy: 0.8800 - val_precision_9: 0.8609 - val_recall_9: 0.9065 - 51s/epoch - 16ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 52s - loss: 0.2313 - accuracy: 0.9087 - precision_9: 0.9051 - recall_9: 0.9130 - val_loss: 0.4229 - val_accuracy: 0.8198 - val_precision_9: 0.9786 - val_recall_9: 0.6539 - 52s/epoch - 17ms/step\n",
            "Training model with 128 filters and 2 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 91s - loss: 0.3094 - accuracy: 0.8730 - precision_10: 0.8699 - recall_10: 0.8772 - val_loss: 0.2241 - val_accuracy: 0.9081 - val_precision_10: 0.9188 - val_recall_10: 0.8952 - 91s/epoch - 29ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 90s - loss: 0.2075 - accuracy: 0.9175 - precision_10: 0.9154 - recall_10: 0.9200 - val_loss: 0.5924 - val_accuracy: 0.7709 - val_precision_10: 0.9743 - val_recall_10: 0.5564 - 90s/epoch - 29ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 89s - loss: 0.1754 - accuracy: 0.9315 - precision_10: 0.9298 - recall_10: 0.9334 - val_loss: 0.1822 - val_accuracy: 0.9275 - val_precision_10: 0.9512 - val_recall_10: 0.9012 - 89s/epoch - 29ms/step\n",
            "Training model with 128 filters and 3 layers...\n",
            "Epoch 1/3\n",
            "3125/3125 - 108s - loss: 0.2535 - accuracy: 0.8958 - precision_11: 0.8925 - recall_11: 0.9001 - val_loss: 0.4326 - val_accuracy: 0.8272 - val_precision_11: 0.9707 - val_recall_11: 0.6748 - 108s/epoch - 35ms/step\n",
            "Epoch 2/3\n",
            "3125/3125 - 106s - loss: 0.1763 - accuracy: 0.9313 - precision_11: 0.9296 - recall_11: 0.9333 - val_loss: 0.3720 - val_accuracy: 0.8502 - val_precision_11: 0.9895 - val_recall_11: 0.7079 - 106s/epoch - 34ms/step\n",
            "Epoch 3/3\n",
            "3125/3125 - 106s - loss: 0.1458 - accuracy: 0.9428 - precision_11: 0.9423 - recall_11: 0.9433 - val_loss: 0.1730 - val_accuracy: 0.9336 - val_precision_11: 0.9299 - val_recall_11: 0.9378 - 106s/epoch - 34ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print table for Accuracy\n",
        "print(\"Validation Accuracy for Different Topologies:\")\n",
        "accuracy_table = results_df.pivot_table(index='Filters', columns='Layers', values='Accuracy', aggfunc='max')\n",
        "print(accuracy_table)\n",
        "\n",
        "# Print table for Validation Loss\n",
        "print(\"\\nValidation Loss for Different Topologies:\")\n",
        "loss_table = results_df.pivot_table(index='Filters', columns='Layers', values='Validation Loss', aggfunc='min')\n",
        "print(loss_table)\n",
        "\n",
        "# Print table for Precision\n",
        "print(\"\\nValidation Precision for Different Topologies:\")\n",
        "precision_table = results_df.pivot_table(index='Filters', columns='Layers', values='Precision', aggfunc='max')\n",
        "print(precision_table)\n",
        "\n",
        "# Print table for Recall\n",
        "print(\"\\nValidation Recall for Different Topologies:\")\n",
        "recall_table = results_df.pivot_table(index='Filters', columns='Layers', values='Recall', aggfunc='max')\n",
        "print(recall_table)\n",
        "\n",
        "# Print table for F1 Score\n",
        "print(\"\\nValidation F1 Score for Different Topologies:\")\n",
        "f1_table = results_df.pivot_table(index='Filters', columns='Layers', values='F1 Score', aggfunc='max')\n",
        "print(f1_table)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OlgdF1pD25W",
        "outputId": "d55e28e3-ea3b-46af-d95c-2e2642042d80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy for Different Topologies:\n",
            "Layers         1        2        3\n",
            "Filters                           \n",
            "16       0.90850  0.88810  0.87670\n",
            "32       0.90355  0.91765  0.89160\n",
            "64       0.69420  0.87565  0.92970\n",
            "128      0.81980  0.92750  0.93355\n",
            "\n",
            "Validation Loss for Different Topologies:\n",
            "Layers          1         2         3\n",
            "Filters                              \n",
            "16       0.242893  0.270710  0.304444\n",
            "32       0.241497  0.208657  0.276559\n",
            "64       0.987343  0.313845  0.181207\n",
            "128      0.422880  0.182234  0.173021\n",
            "\n",
            "Validation Precision for Different Topologies:\n",
            "Layers          1         2         3\n",
            "Filters                              \n",
            "16       0.905338  0.833936  0.823237\n",
            "32       0.879812  0.951465  0.981791\n",
            "64       0.981886  0.973170  0.936155\n",
            "128      0.978599  0.951235  0.929896\n",
            "\n",
            "Validation Recall for Different Topologies:\n",
            "Layers        1       2       3\n",
            "Filters                        \n",
            "16       0.9124  0.9692  0.9594\n",
            "32       0.9348  0.8802  0.7980\n",
            "64       0.3957  0.7726  0.9223\n",
            "128      0.6539  0.9012  0.9378\n",
            "\n",
            "Validation F1 Score for Different Topologies:\n",
            "Layers          1         2         3\n",
            "Filters                              \n",
            "16       0.908855  0.896494  0.886118\n",
            "32       0.906473  0.914446  0.880406\n",
            "64       0.564077  0.861363  0.929176\n",
            "128      0.783959  0.925542  0.933831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort by Accuracy (descending) and Validation Loss (ascending)\n",
        "best_topology_df = results_df.sort_values(by=['Accuracy', 'Validation Loss'], ascending=[False, True])\n",
        "\n",
        "# Extract the best topology\n",
        "best_topology = best_topology_df.iloc[0]\n",
        "\n",
        "# Print the details of the best-performing topology\n",
        "print(\"Topology with Highest Accuracy and Minimal Loss:\")\n",
        "print(f\"Filters: {best_topology['Filters']}\")\n",
        "print(f\"Layers: {best_topology['Layers']}\")\n",
        "print(f\"Accuracy: {best_topology['Accuracy']:.4f}\")\n",
        "print(f\"Precision: {best_topology['Precision']:.4f}\")\n",
        "print(f\"Recall: {best_topology['Recall']:.4f}\")\n",
        "print(f\"F1 Score: {best_topology['F1 Score']:.4f}\")\n",
        "print(f\"Validation Loss: {best_topology['Validation Loss']:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aeFr9mfUFCft",
        "outputId": "002f0158-6abb-427f-c247-30047e654eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topology with Highest Accuracy and Minimal Loss:\n",
            "Filters: 128.0\n",
            "Layers: 3.0\n",
            "Accuracy: 0.9336\n",
            "Precision: 0.9299\n",
            "Recall: 0.9378\n",
            "F1 Score: 0.9338\n",
            "Validation Loss: 0.1730\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define the feature extractor with 128 filters and 3 layers\n",
        "def build_feature_extractor():\n",
        "    feature_extractor = models.Sequential([\n",
        "        layers.Rescaling(1./255, input_shape=(32, 32, 3)),  # Normalize input\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten()\n",
        "    ])\n",
        "    return feature_extractor\n"
      ],
      "metadata": {
        "id": "TeyWN94HFCjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to build the dense model with varying architectures\n",
        "def build_dense_model(feature_extractor, neurons, num_layers, activation):\n",
        "    model = models.Sequential()\n",
        "    model.add(feature_extractor)  # Add the feature extractor\n",
        "    for _ in range(num_layers):\n",
        "        model.add(layers.Dense(neurons, activation=activation))  # Add dense layers with given neurons and activation\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))  # Final output layer with sigmoid activation for binary classification\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n"
      ],
      "metadata": {
        "id": "zi5J8dZhFCo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the list of neurons and dense layers to explore\n",
        "neurons_list = [32, 64, 128, 256, 512, 1024, 2048, 4096]\n",
        "dense_layers = [1, 2, 3]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "\n",
        "# Load training and validation datasets (Ensure X_train, y_train, X_test, y_test are ready)\n",
        "# Example: X_train, y_train, X_test, y_test = your_dataset_loading_function()\n"
      ],
      "metadata": {
        "id": "M47fUNzsH0El"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract features and labels from the train and validation datasets\n",
        "def extract_data_from_dataset(dataset):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for image_batch, label_batch in dataset:\n",
        "        images.append(image_batch.numpy())\n",
        "        labels.append(label_batch.numpy())\n",
        "    return np.concatenate(images), np.concatenate(labels)\n",
        "\n",
        "# Extract data\n",
        "X_train, y_train = extract_data_from_dataset(train_dataset)\n",
        "X_test, y_test = extract_data_from_dataset(val_dataset)\n"
      ],
      "metadata": {
        "id": "RoVq3-ttH0Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Iterate through different topologies and evaluate\n",
        "for neurons in neurons_list:\n",
        "    for num_layers in dense_layers:\n",
        "        # Train with ReLU activation\n",
        "        model_relu = build_dense_model(build_feature_extractor(), neurons, num_layers, 'relu')\n",
        "        model_relu.fit(X_train, y_train, epochs=1, batch_size=1, verbose=0)\n",
        "        y_pred_relu = model_relu.predict(X_test).round()  # Get binary predictions\n",
        "\n",
        "        # Calculate metrics for ReLU model\n",
        "        accuracy_relu = accuracy_score(y_test, y_pred_relu)\n",
        "        precision_relu = precision_score(y_test, y_pred_relu)\n",
        "        recall_relu = recall_score(y_test, y_pred_relu)\n",
        "        f1_relu = f1_score(y_test, y_pred_relu)\n",
        "        loss_relu = model_relu.evaluate(X_test, y_test, verbose=0)[0]\n",
        "\n",
        "        results.append({\n",
        "            'Neurons': neurons,\n",
        "            'Dense Layers': num_layers,\n",
        "            'Activation': 'ReLU',\n",
        "            'Accuracy': accuracy_relu,\n",
        "            'Loss': loss_relu,\n",
        "            'Precision': precision_relu,\n",
        "            'Recall': recall_relu,\n",
        "            'F1 Score': f1_relu\n",
        "        })\n",
        "\n",
        "        # Train with Sigmoid activation\n",
        "        model_sigmoid = build_dense_model(build_feature_extractor(), neurons, num_layers, 'sigmoid')\n",
        "        model_sigmoid.fit(X_train, y_train, epochs=1, batch_size=1, verbose=0)\n",
        "        y_pred_sigmoid = model_sigmoid.predict(X_test).round()\n",
        "\n",
        "        # Calculate metrics for Sigmoid model\n",
        "        accuracy_sigmoid = accuracy_score(y_test, y_pred_sigmoid)\n",
        "        precision_sigmoid = precision_score(y_test, y_pred_sigmoid)\n",
        "        recall_sigmoid = recall_score(y_test, y_pred_sigmoid)\n",
        "        f1_sigmoid = f1_score(y_test, y_pred_sigmoid)\n",
        "        loss_sigmoid = model_sigmoid.evaluate(X_test, y_test, verbose=0)[0]\n",
        "\n",
        "        results.append({\n",
        "            'Neurons': neurons,\n",
        "            'Dense Layers': num_layers,\n",
        "            'Activation': 'Sigmoid',\n",
        "            'Accuracy': accuracy_sigmoid,\n",
        "            'Loss': loss_sigmoid,\n",
        "            'Precision': precision_sigmoid,\n",
        "            'Recall': recall_sigmoid,\n",
        "            'F1 Score': f1_sigmoid\n",
        "        })\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "95UKzSkBH0Hn",
        "outputId": "850f1fb6-74ac-4d44-9941-9b385c643617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 69ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 70ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 71ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e7277ce37c4c>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# Train with ReLU activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel_relu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_dense_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_feature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneurons\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel_relu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my_pred_relu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_relu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Get binary predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    136\u001b[0m   \u001b[0;31m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/core/function/polymorphism/function_type.py\u001b[0m in \u001b[0;36munpack_inputs\u001b[0;34m(self, bound_parameters)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m       flat.extend(\n\u001b[0;32m--> 391\u001b[0;31m           \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_constraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_parameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m       )\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36mto_tensors\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     nest.map_structure(\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0;32mlambda\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_specs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mwrong\u001b[0m \u001b[0mkeyword\u001b[0m \u001b[0marguments\u001b[0m \u001b[0mare\u001b[0m \u001b[0mprovided\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m   \"\"\"\n\u001b[0;32m--> 628\u001b[0;31m   return nest_util.map_structure(\n\u001b[0m\u001b[1;32m    629\u001b[0m       \u001b[0mnest_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1063\u001b[0m   \"\"\"\n\u001b[1;32m   1064\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCORE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_core_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mmodality\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_tf_data_map_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1103\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1104\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest_util.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1103\u001b[0m   return _tf_core_pack_sequence_as(\n\u001b[1;32m   1104\u001b[0m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1105\u001b[0;31m       \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1106\u001b[0m       \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/type_spec.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(spec, v)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     nest.map_structure(\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mlambda\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_component_specs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         self._to_components(value))\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36mto_tensors\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   1079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mto_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInternalCastContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_subtype_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m       raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36mcast\u001b[0;34m(self, value, casting_context)\u001b[0m\n\u001b[1;32m   1109\u001b[0m     \u001b[0mvalue_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mvalue_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_subtype_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_subtype_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor.py\u001b[0m in \u001b[0;36mis_subtype_of\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1002\u001b[0m     return (\n\u001b[1;32m   1003\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m         \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_subtype_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_subtype_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mis_subtype_of\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m     \u001b[0;31m# All Tensors are subtypes of a Tensor with no shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mrank\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"(%s)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m\", \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;34m\"\"\"Returns the rank of this shape, or None if it is unspecified.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert results to a DataFrame for easy visualization\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Create separate tables for each validation metric\n",
        "accuracy_df = results_df[['Neurons', 'Dense Layers', 'Activation', 'Accuracy']].pivot(index='Neurons', columns='Dense Layers', values='Accuracy')\n",
        "loss_df = results_df[['Neurons', 'Dense Layers', 'Activation', 'Loss']].pivot(index='Neurons', columns='Dense Layers', values='Loss')\n",
        "precision_df = results_df[['Neurons', 'Dense Layers', 'Activation', 'Precision']].pivot(index='Neurons', columns='Dense Layers', values='Precision')\n",
        "recall_df = results_df[['Neurons', 'Dense Layers', 'Activation', 'Recall']].pivot(index='Neurons', columns='Dense Layers', values='Recall')\n",
        "f1_df = results_df[['Neurons', 'Dense Layers', 'Activation', 'F1 Score']].pivot(index='Neurons', columns='Dense Layers', values='F1 Score')\n",
        "\n",
        "# Output all tables\n",
        "print(\"Accuracy Metrics:\")\n",
        "print(accuracy_df)\n",
        "print(\"\\nLoss Metrics:\")\n",
        "print(loss_df)\n",
        "print(\"\\nPrecision Metrics:\")\n",
        "print(precision_df)\n",
        "print(\"\\nRecall Metrics:\")\n",
        "print(recall_df)\n",
        "print(\"\\nF1 Score Metrics:\")\n",
        "print(f1_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnsGsfm8H0Pc",
        "outputId": "9a783611-725c-4fe1-85a1-14442be1cafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy:\n",
            "Dense Layers     1     2     3\n",
            "          32 91.80 92.28 92.89\n",
            "          64 91.00 91.55 93.18\n",
            "         128 90.41 91.81 91.80\n",
            "         256 90.20 92.00 92.92\n",
            "         512 92.42 92.53 90.57\n",
            "        1024 91.75 92.11 90.02\n",
            "        2048 91.06 91.09 92.54\n",
            "        4096 91.66 92.28 93.08\n",
            "\n",
            "Validation Loss:\n",
            "Dense Layers     1     2     3\n",
            "          32 0.178 0.171 0.181\n",
            "          64 0.171 0.184 0.185\n",
            "         128 0.194 0.198 0.177\n",
            "         256 0.187 0.196 0.173\n",
            "         512 0.172 0.185 0.183\n",
            "        1024 0.190 0.195 0.184\n",
            "        2048 0.184 0.194 0.193\n",
            "        4096 0.179 0.171 0.195\n",
            "\n",
            "Validation Precision:\n",
            "Dense Layers     1     2     3\n",
            "          32 0.915 0.931 0.912\n",
            "          64 0.928 0.911 0.950\n",
            "         128 0.928 0.949 0.935\n",
            "         256 0.916 0.918 0.914\n",
            "         512 0.944 0.941 0.939\n",
            "        1024 0.924 0.946 0.940\n",
            "        2048 0.945 0.929 0.924\n",
            "        4096 0.927 0.939 0.944\n",
            "\n",
            "Validation Recall:\n",
            "Dense Layers     1     2     3\n",
            "          32 0.949 0.938 0.918\n",
            "          64 0.945 0.938 0.931\n",
            "         128 0.947 0.911 0.936\n",
            "         256 0.934 0.937 0.931\n",
            "         512 0.938 0.941 0.920\n",
            "        1024 0.926 0.932 0.947\n",
            "        2048 0.937 0.932 0.914\n",
            "        4096 0.916 0.948 0.946\n",
            "\n",
            "Validation F1 Score:\n",
            "Dense Layers     1     2     3\n",
            "          32 0.940 0.932 0.936\n",
            "          64 0.923 0.925 0.922\n",
            "         128 0.922 0.924 0.934\n",
            "         256 0.921 0.935 0.935\n",
            "         512 0.939 0.924 0.931\n",
            "        1024 0.938 0.926 0.938\n",
            "        2048 0.935 0.925 0.938\n",
            "        4096 0.939 0.927 0.924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Reshape the data for easy filtering and merge them\n",
        "accuracy_data_melted = accuracy_df.melt(id_vars='Neurons', value_vars=['Layer 1', 'Layer 2', 'Layer 3'],\n",
        "                                         var_name='Layer', value_name='Accuracy')\n",
        "loss_data_melted = loss_df.melt(id_vars='Neurons', value_vars=['Layer 1', 'Layer 2', 'Layer 3'],\n",
        "                                var_name='Layer', value_name='Loss')\n",
        "\n",
        "# Combine accuracy and loss data\n",
        "accuracy_data_melted['Layer'] = accuracy_data_melted['Layer'].str.extract('(\\d)').astype(int)\n",
        "loss_data_melted['Layer'] = loss_data_melted['Layer'].str.extract('(\\d)').astype(int)\n",
        "combined_data = pd.merge(accuracy_data_melted, loss_data_melted, on=['Neurons', 'Layer'])\n",
        "\n",
        "# Sort by Loss first, and then by Accuracy\n",
        "sorted_combined_data = combined_data.sort_values(by=['Loss', 'Accuracy'], ascending=[True, False])\n",
        "\n",
        "# Get the best topology with least loss and highest accuracy\n",
        "best_topology = sorted_combined_data.iloc[0]\n",
        "\n",
        "# Print the result\n",
        "print(\"Best Topology based on Least Loss and Highest Accuracy:\")\n",
        "print(f\"Neurons: {best_topology['Neurons']}\")\n",
        "print(f\"Layer: {best_topology['Layer']}\")\n",
        "print(f\"Accuracy: {best_topology['Accuracy']:.2f}\")\n",
        "print(f\"Loss: {best_topology['Loss']:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCucySAPH0M3",
        "outputId": "31701821-87c5-4c45-ab70-b63b86e879a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Topology based on Least Loss and Highest Accuracy:\n",
            "Neurons: 32.0\n",
            "Layer: 2.0\n",
            "Accuracy: 92.28\n",
            "Loss: 0.171\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7TFMGaLyFGQd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}